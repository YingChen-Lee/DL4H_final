{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3988,
     "status": "ok",
     "timestamp": 1652040087667,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "D-uf6ZwpENIy",
    "outputId": "fd8bdeac-db7d-4e48-81a1-21e8bf0ee862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n%cd /content/drive/MyDrive/598-DLH/tensor_exports\\n%ls\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/598-DLH/tensor_exports\n",
    "%ls\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2340,
     "status": "ok",
     "timestamp": 1652040089998,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "xjhXSwM0ESGi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from math import ceil\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4989,
     "status": "ok",
     "timestamp": 1652040094983,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "9v44rDBvEl4x"
   },
   "outputs": [],
   "source": [
    "final_tensor = torch.load('../tensor_exports/data_tensor_chart_demog.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1652040094984,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "nXP2cF2HEu7q",
    "outputId": "4ef4dbea-eeb0-43b0-8839-0dd9297805fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1541, 5, 720, 58])\n"
     ]
    }
   ],
   "source": [
    "print(final_tensor.shape)\n",
    "BATCH_SIZE=100\n",
    "FEATURE_SIZE = final_tensor.shape[-1]\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSDSnS7eRCf_"
   },
   "source": [
    "# Try to get the hadm_idx_to_hadm_id first\n",
    "so that we can get the is_sepsis label for that hadm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1652040094985,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "EX3_b8vmr_5B",
    "outputId": "34a4f2ab-49a9-4e3a-c350-dfcc9e5d3af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%cd ../mimic\\n%ls\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%cd ../mimic\n",
    "%ls\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1652040094987,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "IdgMI_MNsKgL"
   },
   "outputs": [],
   "source": [
    "final_icustays_details = pd.read_pickle('final_icustays_details.pkl')\n",
    "def get_idx_to_hadm_index_dict(values_pdSeries):\n",
    "    return {i:v for i, v in enumerate(list(values_pdSeries.unique()))}\n",
    "    \n",
    "hadm_idx_id_dict = get_idx_to_hadm_index_dict(final_icustays_details['hadm_id'])\n",
    "hadm_sepsis = pd.read_pickle('hadm_sepsis.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1652040109425,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "8uApVIt4vjAU"
   },
   "outputs": [],
   "source": [
    "hadm_id_isSepsis_dict = dict(zip(hadm_sepsis.hadm_id, hadm_sepsis.is_sepsis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMB33ywaYOSD"
   },
   "source": [
    "# DataLoadder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1652040112579,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "KJ6q-oT7YPd3"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_tensor, hadm_id_isSepsis_dict, hadm_idx_id_dict):\n",
    "        self.data_tensor = data_tensor\n",
    "        self.hadm_id_isSepsis_dict = hadm_id_isSepsis_dict\n",
    "        self.hadm_idx_id_dict = hadm_idx_id_dict\n",
    "        self._get_available_icu_stays()\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.available_icu_stays)\n",
    "\n",
    "    def _get_available_icu_stays(self): ## ICU stays that are not padded\n",
    "        self.available_icu_stays = []\n",
    "        for hadm_idx in range(self.data_tensor.shape[0]):\n",
    "            for icu_idx in range(self.data_tensor.shape[1]):\n",
    "                if self.data_tensor[hadm_idx, icu_idx, 0, 2] != 0: ## If the first ICU stay's length of stay (los) is zero, then it's padded\n",
    "                    self.available_icu_stays.append((hadm_idx, icu_idx))\n",
    "\n",
    "    def _get_sofa_score(self, index, value):\n",
    "        if index == 57: ## Platelets\n",
    "            if value >= 150:\n",
    "                return 0\n",
    "            elif value >= 100:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        elif index == 34: ## creatinie  # => seems to over estimate\n",
    "            if value < 1.2:\n",
    "                return 0\n",
    "            elif value < 2:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        elif index == 20: ## FiO2\n",
    "            return 2 if value >=53.3 else 0\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "       \n",
    "\n",
    "    def _get_sepsis_onset_hour_or_last_hour(self, x):\n",
    "        hour_idx = 0\n",
    "        for hour in x:\n",
    "            SOFA_score = self._get_sofa_score(57, hour[57]) + self._get_sofa_score(20, hour[20]) + self._get_sofa_score(34, hour[34])\n",
    "            if SOFA_score >= 2:\n",
    "                return hour_idx, torch.tensor(1, dtype=torch.float32)\n",
    "            hour_idx += 1\n",
    "        return int(x[0][2]*24), torch.tensor(0, dtype=torch.float32) ## Get the first hour's 3rd feature, which is length of stay of this icu\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        target_hadm_idx, target_icu_idx = self.available_icu_stays[index]\n",
    "        x = self.data_tensor[target_hadm_idx, target_icu_idx] \n",
    "\n",
    "        l = int(x[0][2]*24) ## Get the first hour's 3rd feature, which is length of stay of this icu\n",
    "        target_hadm_id = self.hadm_idx_id_dict[target_hadm_idx]\n",
    "        if self.hadm_id_isSepsis_dict[target_hadm_id] == False:\n",
    "            y = torch.tensor(0, dtype=torch.float32)\n",
    "        else:\n",
    "            l, y = self._get_sepsis_onset_hour_or_last_hour(x)\n",
    "        return x, y, l\n",
    "\n",
    "dataset = CustomDataset(final_tensor, hadm_id_isSepsis_dict, hadm_idx_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652040114491,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "edi4AX1HxQYj",
    "outputId": "4e8f20dc-51e4-4461-9a35-6e3544b37fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train dataset: 1434\n",
      "length of test dataset: 359\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "split = int(len(dataset) * 0.8)\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, test_dataset = random_split(dataset, lengths)\n",
    "print(\"length of train dataset:\", len(train_dataset))\n",
    "print(\"length of test dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652040115267,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "A1QkPsVq0eyP"
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sequences, labels, lengths = zip(*data)\n",
    "    x = torch.stack(sequences, dim=0)\n",
    "    y = torch.tensor(labels, dtype=torch.float)  \n",
    "    l = torch.tensor(lengths, dtype=torch.long)\n",
    "    return x, y, l\n",
    "  \n",
    "def get_last_visit(hidden_states, length):\n",
    "    return hidden_states[range(hidden_states.shape[0]), length - 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1652040120293,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "1LQblsJW6OV2",
    "outputId": "d892be87-f5fe-4c1d-b808-215816f97d51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 720, 58])\n",
      "torch.Size([2])\n",
      "tensor([24, 77])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## test\n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(train_dataset, batch_size=2, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, y, l = next(loader_iter)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1652040122779,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "PoH236Tm6V8l"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1652040124851,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "hbvl10-4_JTn"
   },
   "outputs": [],
   "source": [
    "def get_last_visit(hidden_states, length):\n",
    "    return hidden_states[range(hidden_states.shape[0]), length - 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1652040126716,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "jVhv9jOV_7vt",
    "outputId": "50c79f69-7e39-4685-cb1b-20c2cd4d8ece"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## TEST \\nimport random\\nmax_num_visits = 10\\nbatch_size = 16\\nhidden_dim = 100\\n\\nhidden_states = torch.randn((batch_size, max_num_visits, hidden_dim))\\nlengths = torch.tensor([random.randint(1, max_num_visits) for _ in range(batch_size)])\\nout = get_last_visit(hidden_states, lengths)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## TEST \n",
    "import random\n",
    "max_num_visits = 10\n",
    "batch_size = 16\n",
    "hidden_dim = 100\n",
    "\n",
    "hidden_states = torch.randn((batch_size, max_num_visits, hidden_dim))\n",
    "lengths = torch.tensor([random.randint(1, max_num_visits) for _ in range(batch_size)])\n",
    "out = get_last_visit(hidden_states, lengths)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1652040128866,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "zXklYM_5-_Cz",
    "outputId": "ce111b6b-b58e-4a05-b790-f3eb66bd0d9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): LSTM(58, 800, batch_first=True)\n",
       "  (fc): Linear(in_features=800, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size = FEATURE_SIZE, hidden_size = 800, batch_first=True)\n",
    "        self.fc = nn.Linear(800, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "  \n",
    "    def forward(self, x, length):\n",
    "        batch_size = x.shape[0]\n",
    "        output, _ = self.rnn(x)\n",
    "        true_h_n = get_last_visit(output, length)\n",
    "        logits =torch.relu(self.fc(true_h_n))\n",
    "        probs = self.softmax(logits)\n",
    "        '''\n",
    "        pred = []\n",
    "        for res in probs:\n",
    "          pred.append(res)\n",
    "        '''\n",
    "        return probs\n",
    "\n",
    "model = RNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1652040131308,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "jf3_FFy0FRwd"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1652040133482,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "txbEHx83F0qj"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "#input: Y_score,Y_pred,Y_true\n",
    "#output: accuracy, auc, precision, recall, f1-score\n",
    "def classification_metrics(Y_score, Y_pred, Y_true):\n",
    "    auc, precision, recall =   roc_auc_score(Y_true, Y_score), \\\n",
    "                               precision_score(Y_true, Y_pred), \\\n",
    "                                recall_score(Y_true, Y_pred)\n",
    "    return auc, precision, recall\n",
    "\n",
    "\n",
    "#input: model, loader\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_y_true = torch.LongTensor()\n",
    "    all_y_pred = torch.LongTensor()\n",
    "    all_y_score = torch.FloatTensor()\n",
    "    \n",
    "    for x, y, l in loader:\n",
    "        # pass the input through the model\n",
    "        y_hat = model(x, l)\n",
    "        y_hat = y_hat.select(dim=1, index=0)\n",
    "        # convert shape from [batch size, 1] to [batch size]\n",
    "        y_pred = (y_hat > 0.5).type(torch.float)\n",
    "        \n",
    "        y_hat = torch.nan_to_num(y_hat)\n",
    "\n",
    "        all_y_true = torch.cat((all_y_true, y.to('cpu')), dim=0)\n",
    "        all_y_pred = torch.cat((all_y_pred,  y_pred.to('cpu')), dim=0)\n",
    "        all_y_score = torch.cat((all_y_score,  y_hat.to('cpu')), dim=0)\n",
    "    \n",
    "    all_y_true = torch.cat((torch.tensor([1]), all_y_true.to('cpu')), dim=0) ## According to the paper, it up-scaling the septic cases\n",
    "    all_y_pred = torch.cat((torch.tensor([1]), all_y_pred.to('cpu')), dim=0)\n",
    "    all_y_score = torch.cat((torch.tensor([1]), all_y_score.to('cpu')), dim=0)\n",
    "\n",
    "    auc, precision, recall = classification_metrics(all_y_score.detach().numpy(), \n",
    "                                                             all_y_pred.detach().numpy(), \n",
    "                                                             all_y_true.detach().numpy())\n",
    "    print(f\"auc: {auc:.3f}, precision: {precision:.3f}, recall: {recall:.3f}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "L_h8mUiVIsR0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.547, precision: 0.375, recall: 0.078\n"
     ]
    }
   ],
   "source": [
    "train_init = evaluate(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "aborted",
     "timestamp": 1652040095588,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "I69GcjfWF-Sc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.503746\n",
      "auc: 0.731, precision: 0.733, recall: 0.036\n",
      "auc: 0.725, precision: 0.818, recall: 0.122\n",
      "Epoch: 2 \tTraining Loss: 0.490070\n",
      "auc: 0.750, precision: 0.706, recall: 0.039\n",
      "auc: 0.741, precision: 0.778, recall: 0.095\n",
      "Epoch: 3 \tTraining Loss: 0.465966\n",
      "auc: 0.779, precision: 0.800, recall: 0.039\n",
      "auc: 0.770, precision: 0.750, recall: 0.081\n",
      "Epoch: 4 \tTraining Loss: 0.444488\n",
      "auc: 0.806, precision: 0.812, recall: 0.042\n",
      "auc: 0.798, precision: 0.778, recall: 0.095\n",
      "Epoch: 5 \tTraining Loss: 0.442244\n",
      "auc: 0.832, precision: 0.724, recall: 0.068\n",
      "auc: 0.820, precision: 0.818, recall: 0.122\n",
      "Epoch: 6 \tTraining Loss: 0.436112\n",
      "auc: 0.834, precision: 0.792, recall: 0.062\n",
      "auc: 0.825, precision: 0.778, recall: 0.095\n",
      "Epoch: 7 \tTraining Loss: 0.425274\n",
      "auc: 0.850, precision: 0.800, recall: 0.091\n",
      "auc: 0.848, precision: 0.800, recall: 0.162\n",
      "Epoch: 8 \tTraining Loss: 0.432507\n",
      "auc: 0.845, precision: 0.828, recall: 0.078\n",
      "auc: 0.841, precision: 0.778, recall: 0.095\n",
      "Epoch: 9 \tTraining Loss: 0.402441\n",
      "auc: 0.858, precision: 0.865, recall: 0.104\n",
      "auc: 0.859, precision: 0.818, recall: 0.122\n",
      "Epoch: 10 \tTraining Loss: 0.387404\n",
      "auc: 0.839, precision: 0.804, recall: 0.134\n",
      "auc: 0.829, precision: 0.733, recall: 0.149\n",
      "Epoch: 11 \tTraining Loss: 0.386663\n",
      "auc: 0.877, precision: 0.792, recall: 0.274\n",
      "auc: 0.875, precision: 0.667, recall: 0.243\n",
      "Epoch: 12 \tTraining Loss: 0.365541\n",
      "auc: 0.875, precision: 0.902, recall: 0.121\n",
      "auc: 0.876, precision: 0.917, recall: 0.149\n",
      "Epoch: 13 \tTraining Loss: 0.355489\n",
      "auc: 0.897, precision: 0.964, recall: 0.173\n",
      "auc: 0.897, precision: 1.000, recall: 0.189\n",
      "Epoch: 14 \tTraining Loss: 0.335209\n",
      "auc: 0.893, precision: 0.762, recall: 0.616\n",
      "auc: 0.904, precision: 0.746, recall: 0.635\n",
      "Epoch: 15 \tTraining Loss: 0.374586\n",
      "auc: 0.875, precision: 0.836, recall: 0.199\n",
      "auc: 0.868, precision: 0.737, recall: 0.189\n",
      "Epoch: 16 \tTraining Loss: 0.410064\n",
      "auc: 0.867, precision: 0.786, recall: 0.072\n",
      "auc: 0.878, precision: 0.769, recall: 0.135\n",
      "Epoch: 17 \tTraining Loss: 0.402376\n",
      "auc: 0.847, precision: 0.826, recall: 0.062\n",
      "auc: 0.860, precision: 0.875, recall: 0.095\n",
      "Epoch: 18 \tTraining Loss: 0.393286\n",
      "auc: 0.868, precision: 0.831, recall: 0.176\n",
      "auc: 0.875, precision: 0.789, recall: 0.203\n",
      "Epoch: 19 \tTraining Loss: 0.375995\n",
      "auc: 0.877, precision: 0.731, recall: 0.397\n",
      "auc: 0.885, precision: 0.628, recall: 0.365\n",
      "Epoch: 20 \tTraining Loss: 0.367151\n",
      "auc: 0.895, precision: 0.796, recall: 0.394\n",
      "auc: 0.909, precision: 0.757, recall: 0.378\n",
      "Epoch: 21 \tTraining Loss: 0.361990\n",
      "auc: 0.893, precision: 0.901, recall: 0.296\n",
      "auc: 0.907, precision: 0.810, recall: 0.230\n",
      "Epoch: 22 \tTraining Loss: 0.358208\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "# prep model for training\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y, l in train_loader:\n",
    "        x = torch.nan_to_num(x)\n",
    "        \"\"\" Step 1. clear gradients \"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        \"\"\"  Step 2. perform forward pass using `model`, save the output to y_hat \"\"\"\n",
    "        y_hat = model(x, l)\n",
    "        \"\"\" Step 3. calculate the loss using `criterion`, save the output to loss. \"\"\"\n",
    "        '''\n",
    "        y_list = list(y)\n",
    "        for i in range(len(y_list)):\n",
    "            if y_list[i] > 0.5:\n",
    "                y_list[i] = [float(0), float(1)]\n",
    "            else:\n",
    "                y_list[i] = [float(1), float(0)]\n",
    "        y_true = torch.tensor(y_list,dtype=torch.float)\n",
    "        '''\n",
    "        \n",
    "        #y_hat = torch.nan_to_num(y_hat)\n",
    "        y_hat = torch.select(y_hat, index=0, dim=1)\n",
    "        \n",
    "        loss = criterion(y_hat, y)\n",
    "        \"\"\" Step 4. backward pass \"\"\"\n",
    "        loss.backward()\n",
    "        \"\"\" Step 5. optimization \"\"\"\n",
    "        optimizer.step()\n",
    "        \"\"\" Step 6. record loss \"\"\"\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "    evaluate(model, train_loader)\n",
    "    evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1652040095588,
     "user": {
      "displayName": "李映辰",
      "userId": "02446792374095967699"
     },
     "user_tz": -480
    },
    "id": "Yx3fLKQvJzp1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOVqiOHcvyuZN080Gz1042r",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
