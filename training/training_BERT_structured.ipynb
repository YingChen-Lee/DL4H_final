{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3370,"status":"ok","timestamp":1652052503160,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"D-uf6ZwpENIy","outputId":"ce0db1f6-9e45-4475-fc52-9bc723c256e9"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_8160/3656294305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/598-DLH/Draft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/598-DLH/Draft\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjhXSwM0ESGi"},"outputs":[],"source":["import torch\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timedelta\n","from math import ceil\n","import gzip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SfX7yD-EZAq","outputId":"e24915b9-b81f-4296-b192-d2e00b5ec77f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/mnt/d/CS598DLH/mimic-iii-clinical-database-1.4\n","\u001b[0m\u001b[01;32mADMISSIONS.csv.gz\u001b[0m*          \u001b[01;32mPATIENTS.csv.gz\u001b[0m*\n","\u001b[01;32mCALLOUT.csv.gz\u001b[0m*             \u001b[01;32mPRESCRIPTIONS.csv.gz\u001b[0m*\n","\u001b[01;32mCAREGIVERS.csv.gz\u001b[0m*          \u001b[01;32mPROCEDUREEVENTS_MV.csv.gz\u001b[0m*\n","\u001b[01;32mCHARTEVENTS.csv.gz\u001b[0m*         \u001b[01;32mPROCEDURES_ICD.csv.gz\u001b[0m*\n","\u001b[01;32mCPTEVENTS.csv.gz\u001b[0m*           \u001b[01;32mREADME.md\u001b[0m*\n","\u001b[01;32mDATETIMEEVENTS.csv.gz\u001b[0m*      \u001b[01;32mSERVICES.csv.gz\u001b[0m*\n","\u001b[01;32mDIAGNOSES_ICD.csv.gz\u001b[0m*       \u001b[01;32mSHA256SUMS.txt\u001b[0m*\n","\u001b[01;32mDRGCODES.csv.gz\u001b[0m*            \u001b[01;32mTRANSFERS.csv.gz\u001b[0m*\n","\u001b[01;32mD_CPT.csv.gz\u001b[0m*               \u001b[01;32mchart.pkl\u001b[0m*\n","\u001b[01;32mD_ICD_DIAGNOSES.csv.gz\u001b[0m*     \u001b[01;32mchart_tensor_filled_final.pt.gz\u001b[0m*\n","\u001b[01;32mD_ICD_PROCEDURES.csv.gz\u001b[0m*    \u001b[01;32mchecksum_md5_unzipped.txt\u001b[0m*\n","\u001b[01;32mD_ITEMS.csv\u001b[0m*                \u001b[01;32mchecksum_md5_zipped.txt\u001b[0m*\n","\u001b[01;32mD_ITEMS.csv.gz\u001b[0m*             \u001b[01;32mcleaned_text.pkl\u001b[0m*\n","\u001b[01;32mD_LABITEMS.csv.gz\u001b[0m*          \u001b[01;32mdata_tensor_chart_demog.pt.gz\u001b[0m*\n","\u001b[01;32mICUSTAYS.csv.gz\u001b[0m*            \u001b[01;32mdata_tensor_final.pt\u001b[0m*\n","\u001b[01;32mINPUTEVENTS_CV.csv.gz\u001b[0m*      \u001b[01;32mdata_tensor_final.pt.gz\u001b[0m*\n","\u001b[01;32mINPUTEVENTS_MV.csv.gz\u001b[0m*      \u001b[01;32mfinal_icustay_ids.pkl\u001b[0m*\n","\u001b[01;32mLABEVENTS.csv.gz\u001b[0m*           \u001b[01;32mfinal_icustays_details.pkl\u001b[0m*\n","\u001b[01;32mLICENSE.txt\u001b[0m*                \u001b[01;32mhadm_sepsis.pkl\u001b[0m*\n","\u001b[01;32mMICROBIOLOGYEVENTS.csv.gz\u001b[0m*  \u001b[01;32mnotes_tensor_filled.pt.gz\u001b[0m*\n","\u001b[01;32mNOTEEVENTS.csv.gz\u001b[0m*          \u001b[01;32mnotes_tensor_real.pt.gz\u001b[0m*\n","\u001b[01;32mOUTPUTEVENTS.csv.gz\u001b[0m*        \u001b[01;32mtext_bert_1874862_2083180.pkl\u001b[0m*\n"]}],"source":["%cd mimic-iii-clinical-database-1.4/\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1652052506270,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"Zycz2OXvfbPn","outputId":"229e152f-e096-44a6-8766-6263219b5a74"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/14VE6jxu6gzBuYO9WY79TIloM87C-NZXP/598-DLH/Draft/tensor_exports\n"]}],"source":["%cd tensor_exports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9v44rDBvEl4x"},"outputs":[],"source":["final_tensor = torch.load('data_tensor_final.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70,"status":"ok","timestamp":1652052560047,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"nXP2cF2HEu7q","outputId":"a8f0eb26-776f-4eed-b981-1d0afa593095"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1541, 5, 720, 826])\n"]}],"source":["print(final_tensor.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gLWp_CxlaqMn"},"outputs":[],"source":["FEATURE_SIZE = int(final_tensor.shape[3])\n","BATCH_SIZE=100\n","LEARNING_RATE=1e-2"]},{"cell_type":"markdown","metadata":{"id":"HSDSnS7eRCf_"},"source":["# Try to get the hadm_idx_to_hadm_id first\n","so that we can get the is_sepsis label for that hadm_id"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1652052560050,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"EX3_b8vmr_5B","outputId":"ff3229d5-b805-47a2-dcbc-5aced7252fca"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n%cd ../mimic\\n%ls\\n'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","%cd ../mimic\n","%ls\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IdgMI_MNsKgL"},"outputs":[],"source":["final_icustays_details = pd.read_pickle('final_icustays_details.pkl')\n","def get_idx_to_hadm_index_dict(values_pdSeries):\n","    return {i:v for i, v in enumerate(list(values_pdSeries.unique()))}\n","    \n","hadm_idx_id_dict = get_idx_to_hadm_index_dict(final_icustays_details['hadm_id'])\n","hadm_sepsis = pd.read_pickle('hadm_sepsis.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uApVIt4vjAU"},"outputs":[],"source":["hadm_id_isSepsis_dict = dict(zip(hadm_sepsis.hadm_id, hadm_sepsis.is_sepsis))"]},{"cell_type":"markdown","metadata":{"id":"YMB33ywaYOSD"},"source":["# DataLoadder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJ6q-oT7YPd3"},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, data_tensor, hadm_id_isSepsis_dict, hadm_idx_id_dict):\n","        self.data_tensor = data_tensor\n","        self.hadm_id_isSepsis_dict = hadm_id_isSepsis_dict\n","        self.hadm_idx_id_dict = hadm_idx_id_dict\n","        self._get_available_icu_stays()\n","        return\n","\n","    def __len__(self):\n","        return len(self.available_icu_stays)\n","\n","    def _get_available_icu_stays(self): ## ICU stays that are not padded\n","        self.available_icu_stays = []\n","        for hadm_idx in range(self.data_tensor.shape[0]):\n","            for icu_idx in range(self.data_tensor.shape[1]):\n","                if self.data_tensor[hadm_idx, icu_idx, 0, 2] != 0: ## If the first ICU stay's length of stay (los) is zero, then it's padded\n","                    self.available_icu_stays.append((hadm_idx, icu_idx))\n","\n","    def _get_sofa_score(self, index, value):\n","        if index == 57: ## Platelets\n","            if value >= 150:\n","                return 0\n","            elif value >= 100:\n","                return 1\n","            else:\n","                return 2\n","        elif index == 34: ## creatinie  # => seems to over estimate\n","            if value < 1.2:\n","                return 0\n","            elif value < 2:\n","                return 1\n","            else:\n","                return 2\n","        elif index == 20: ## FiO2\n","            return 2 if value >=53.3 else 0\n","        else:\n","            return 0\n","        \n","       \n","\n","    def _get_sepsis_onset_hour_or_last_hour(self, x):\n","        hour_idx = 0\n","        for hour in x:\n","            SOFA_score = self._get_sofa_score(57, hour[57]) + self._get_sofa_score(20, hour[20]) + self._get_sofa_score(34, hour[34])\n","            if SOFA_score >= 2:\n","                return hour_idx, torch.tensor(1, dtype=torch.float32)\n","            hour_idx += 1\n","        return int(x[0][2]*24), torch.tensor(0, dtype=torch.float32) ## Get the first hour's 3rd feature, which is length of stay of this icu\n","  \n","    def __getitem__(self, index):\n","        target_hadm_idx, target_icu_idx = self.available_icu_stays[index]\n","        x = self.data_tensor[target_hadm_idx, target_icu_idx] \n","\n","        l = int(x[0][2]*24) ## Get the first hour's 3rd feature, which is length of stay of this icu\n","        target_hadm_id = self.hadm_idx_id_dict[target_hadm_idx]\n","        if self.hadm_id_isSepsis_dict[target_hadm_id] == False:\n","            y = torch.tensor(0, dtype=torch.float32)\n","        else:\n","            l, y = self._get_sepsis_onset_hour_or_last_hour(x)\n","        return x, y, l\n","\n","dataset = CustomDataset(final_tensor[:200,:,:,:].float(), hadm_id_isSepsis_dict, hadm_idx_id_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59,"status":"ok","timestamp":1652052560053,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"edi4AX1HxQYj","outputId":"5a801028-3c5c-4996-b919-c98330874c10"},"outputs":[{"name":"stdout","output_type":"stream","text":["length of train dataset: 194\n","length of test dataset: 49\n"]}],"source":["from torch.utils.data.dataset import random_split\n","\n","split = int(len(dataset) * 0.8)\n","lengths = [split, len(dataset) - split]\n","train_dataset, test_dataset = random_split(dataset, lengths)\n","print(\"length of train dataset:\", len(train_dataset))\n","print(\"length of test dataset:\", len(test_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1QkPsVq0eyP"},"outputs":[],"source":["def collate_fn(data):\n","    sequences, labels, lengths = zip(*data)\n","    x = torch.stack(sequences, dim=0)\n","    y = torch.tensor(labels, dtype=torch.float)  \n","    l = torch.tensor(lengths, dtype=torch.long)\n","    return x, y, l\n","  \n","def get_last_visit(hidden_states, length):\n","    return hidden_states[range(hidden_states.shape[0]), length - 1, :]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1652052560056,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"1LQblsJW6OV2","outputId":"e3cd3aa7-d971-4772-c0ea-610841166cda"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 720, 826])\n","torch.Size([2])\n","tensor([306,  54])\n"]}],"source":["\n","## test\n","from torch.utils.data import DataLoader\n","loader = DataLoader(train_dataset, batch_size=2, collate_fn=collate_fn)\n","loader_iter = iter(loader)\n","x, y, l = next(loader_iter)\n","\n","print(x.shape)\n","print(y.shape)\n","print(l)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoH236Tm6V8l"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbvl10-4_JTn"},"outputs":[],"source":["def get_last_visit(hidden_states, length):\n","    return hidden_states[range(hidden_states.shape[0]), length - 1, :]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1652052560060,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"jVhv9jOV_7vt","outputId":"123f6a31-be61-44be-e991-d69cd3ce9cf5"},"outputs":[{"data":{"text/plain":["'\\n## TEST \\nimport random\\nmax_num_visits = 10\\nbatch_size = 16\\nhidden_dim = 100\\n\\nhidden_states = torch.randn((batch_size, max_num_visits, hidden_dim))\\nlengths = torch.tensor([random.randint(1, max_num_visits) for _ in range(batch_size)])\\nout = get_last_visit(hidden_states, lengths)\\n'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","## TEST \n","import random\n","max_num_visits = 10\n","batch_size = 16\n","hidden_dim = 100\n","\n","hidden_states = torch.randn((batch_size, max_num_visits, hidden_dim))\n","lengths = torch.tensor([random.randint(1, max_num_visits) for _ in range(batch_size)])\n","out = get_last_visit(hidden_states, lengths)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":649,"status":"ok","timestamp":1652053023590,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"zXklYM_5-_Cz","outputId":"5a720cbe-663b-4ac8-ba25-a1dac17f2f15"},"outputs":[{"data":{"text/plain":["RNN(\n","  (rnn): LSTM(826, 800, batch_first=True)\n","  (fc): Linear(in_features=800, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","class RNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.rnn = nn.LSTM(input_size = FEATURE_SIZE, hidden_size = 800, batch_first=True)\n","        self.fc = nn.Linear(800, 2)\n","        self.softmax = nn.Softmax(dim=1)\n","  \n","    def forward(self, x, length):\n","        batch_size = x.shape[0]\n","        # x = x.to(torch.float16)\n","        output, _ = self.rnn(x)\n","        true_h_n = get_last_visit(output, length)\n","        logits = torch.relu(self.fc(true_h_n))\n","        probs = self.softmax(logits)\n","        '''\n","        pred = []\n","        for res in probs:\n","          pred.append(res)\n","        '''\n","        return probs\n","\n","model = RNN()\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jf3_FFy0FRwd"},"outputs":[],"source":["criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txbEHx83F0qj"},"outputs":[],"source":["from sklearn.metrics import *\n","\n","#input: Y_score,Y_pred,Y_true\n","#output: accuracy, auc, precision, recall, f1-score\n","def classification_metrics(Y_score, Y_pred, Y_true):\n","    auc, precision, recall =   roc_auc_score(Y_true, Y_score), \\\n","                               precision_score(Y_true, Y_pred), \\\n","                                recall_score(Y_true, Y_pred)\n","    return auc, precision, recall\n","\n","\n","#input: model, loader\n","def evaluate(model, loader):\n","    model.eval()\n","    all_y_true = torch.LongTensor()\n","    all_y_pred = torch.LongTensor()\n","    all_y_score = torch.FloatTensor()\n","    \n","\n","    for x, y, l in loader:\n","\n","        # pass the input through the model\n","        y_hat = model(x, l)\n","        y_hat = y_hat.select(dim=1, index=0)\n","        # convert shape from [batch size, 1] to [batch size]\n","        y_pred = (y_hat > 0.5).type(torch.float16)\n","        \n","        y_hat = torch.nan_to_num(y_hat)\n","\n","        all_y_true = torch.cat((all_y_true, y.to('cpu')), dim=0)\n","        all_y_pred = torch.cat((all_y_pred,  y_pred.to('cpu')), dim=0)\n","        all_y_score = torch.cat((all_y_score,  y_hat.to('cpu')), dim=0)\n","    \n","    all_y_true = torch.cat((torch.tensor([1]), all_y_true.to('cpu')), dim=0) ## According to the paper, it up-scaling the septic cases\n","    all_y_pred = torch.cat((torch.tensor([1]), all_y_pred.to('cpu')), dim=0)\n","    all_y_score = torch.cat((torch.tensor([1]), all_y_score.to('cpu')), dim=0)\n","\n","    auc, precision, recall = classification_metrics(all_y_score.detach().numpy(), \n","                                                             all_y_pred.detach().numpy(), \n","                                                             all_y_true.detach().numpy())\n","    print(f\"auc: {auc:.3f}, precision: {precision:.3f}, recall: {recall:.3f}\")\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_h8mUiVIsR0"},"outputs":[],"source":["train_init = evaluate(model, train_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1652052561212,"user":{"displayName":"Ying-Chen Lee","userId":"16343670133736057324"},"user_tz":-480},"id":"I69GcjfWF-Sc","outputId":"a1b1efc8-2c7e-4510-d1f9-3c93c4c89081"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1 \tTraining Loss: 0.647068\n","auc: 0.559, precision: 1.000, recall: 0.018\n","auc: 0.560, precision: 1.000, recall: 0.067\n","Epoch: 2 \tTraining Loss: 0.656496\n","Epoch: 3 \tTraining Loss: 0.606286\n","auc: 0.497, precision: 1.000, recall: 0.018\n","auc: 0.389, precision: 1.000, recall: 0.067\n","Epoch: 4 \tTraining Loss: 0.589493\n","Epoch: 5 \tTraining Loss: 0.599730\n","auc: 0.512, precision: 1.000, recall: 0.018\n","auc: 0.501, precision: 1.000, recall: 0.067\n","Epoch: 6 \tTraining Loss: 0.584686\n","Epoch: 7 \tTraining Loss: 0.585993\n","auc: 0.645, precision: 1.000, recall: 0.018\n","auc: 0.657, precision: 1.000, recall: 0.067\n","Epoch: 8 \tTraining Loss: 0.584771\n","Epoch: 9 \tTraining Loss: 0.585220\n","auc: 0.600, precision: 1.000, recall: 0.018\n","auc: 0.625, precision: 1.000, recall: 0.067\n","Epoch: 10 \tTraining Loss: 0.584723\n","Epoch: 11 \tTraining Loss: 0.585908\n","auc: 0.583, precision: 1.000, recall: 0.018\n","auc: 0.545, precision: 1.000, recall: 0.067\n","Epoch: 12 \tTraining Loss: 0.583198\n","Epoch: 13 \tTraining Loss: 0.584104\n","auc: 0.545, precision: 1.000, recall: 0.018\n","auc: 0.507, precision: 1.000, recall: 0.067\n","Epoch: 14 \tTraining Loss: 0.585983\n","Epoch: 15 \tTraining Loss: 0.583132\n","auc: 0.601, precision: 1.000, recall: 0.018\n","auc: 0.532, precision: 1.000, recall: 0.067\n","Epoch: 16 \tTraining Loss: 0.582544\n","Epoch: 17 \tTraining Loss: 0.581260\n","auc: 0.579, precision: 1.000, recall: 0.018\n","auc: 0.556, precision: 1.000, recall: 0.067\n","Epoch: 18 \tTraining Loss: 0.581481\n","Epoch: 19 \tTraining Loss: 0.581344\n","auc: 0.575, precision: 1.000, recall: 0.018\n","auc: 0.573, precision: 1.000, recall: 0.067\n","Epoch: 20 \tTraining Loss: 0.580914\n","Epoch: 21 \tTraining Loss: 0.582516\n","auc: 0.601, precision: 1.000, recall: 0.018\n","auc: 0.555, precision: 1.000, recall: 0.067\n","Epoch: 22 \tTraining Loss: 0.590114\n","Epoch: 23 \tTraining Loss: 0.582599\n","auc: 0.551, precision: 1.000, recall: 0.018\n","auc: 0.561, precision: 1.000, recall: 0.067\n","Epoch: 24 \tTraining Loss: 0.586939\n","Epoch: 25 \tTraining Loss: 0.583489\n","auc: 0.552, precision: 1.000, recall: 0.018\n","auc: 0.574, precision: 1.000, recall: 0.067\n","Epoch: 26 \tTraining Loss: 0.588520\n","Epoch: 27 \tTraining Loss: 0.591619\n","auc: 0.587, precision: 1.000, recall: 0.018\n","auc: 0.584, precision: 1.000, recall: 0.067\n","Epoch: 28 \tTraining Loss: 0.586817\n","Epoch: 29 \tTraining Loss: 0.590699\n","auc: 0.557, precision: 1.000, recall: 0.018\n","auc: 0.608, precision: 1.000, recall: 0.067\n","Epoch: 30 \tTraining Loss: 0.583169\n","Epoch: 31 \tTraining Loss: 0.587023\n","auc: 0.556, precision: 1.000, recall: 0.018\n","auc: 0.582, precision: 1.000, recall: 0.067\n","Epoch: 32 \tTraining Loss: 0.584146\n","Epoch: 33 \tTraining Loss: 0.586054\n","auc: 0.547, precision: 1.000, recall: 0.018\n","auc: 0.583, precision: 1.000, recall: 0.067\n","Epoch: 34 \tTraining Loss: 0.583962\n","Epoch: 35 \tTraining Loss: 0.592010\n","auc: 0.547, precision: 1.000, recall: 0.018\n","auc: 0.582, precision: 1.000, recall: 0.067\n","Epoch: 36 \tTraining Loss: 0.595440\n","Epoch: 37 \tTraining Loss: 0.585589\n","auc: 0.547, precision: 1.000, recall: 0.018\n","auc: 0.518, precision: 1.000, recall: 0.067\n","Epoch: 38 \tTraining Loss: 0.584526\n","Epoch: 39 \tTraining Loss: 0.579947\n","auc: 0.604, precision: 1.000, recall: 0.018\n","auc: 0.560, precision: 1.000, recall: 0.067\n","Epoch: 40 \tTraining Loss: 0.592922\n","Epoch: 41 \tTraining Loss: 0.580722\n","auc: 0.547, precision: 1.000, recall: 0.018\n","auc: 0.509, precision: 1.000, recall: 0.067\n","Epoch: 42 \tTraining Loss: 0.599255\n","Epoch: 43 \tTraining Loss: 0.587453\n","auc: 0.547, precision: 1.000, recall: 0.018\n","auc: 0.510, precision: 1.000, recall: 0.067\n","Epoch: 44 \tTraining Loss: 0.594371\n","Epoch: 45 \tTraining Loss: 0.584875\n","auc: 0.547, precision: 1.000, recall: 0.018\n","auc: 0.518, precision: 1.000, recall: 0.067\n","Epoch: 46 \tTraining Loss: 0.589884\n","Epoch: 47 \tTraining Loss: 0.590072\n","auc: 0.547, precision: 1.000, recall: 0.018\n","auc: 0.520, precision: 1.000, recall: 0.067\n","Epoch: 48 \tTraining Loss: 0.585095\n","Epoch: 49 \tTraining Loss: 0.584591\n","auc: 0.547, precision: 1.000, recall: 0.018\n","auc: 0.520, precision: 1.000, recall: 0.067\n","Epoch: 50 \tTraining Loss: 0.585068\n"]}],"source":["n_epochs = 50\n","counter = 0\n","# prep model for training\n","for epoch in range(n_epochs):\n","    model.train()\n","    train_loss = 0\n","    for x, y, l in train_loader:\n","        x = torch.nan_to_num(x)\n","        \"\"\" Step 1. clear gradients \"\"\"\n","        optimizer.zero_grad()\n","        \"\"\"  Step 2. perform forward pass using `model`, save the output to y_hat \"\"\"\n","        y_hat = model(x, l)\n","        \"\"\" Step 3. calculate the loss using `criterion`, save the output to loss. \"\"\"\n","        \n","        #y_hat = torch.nan_to_num(y_hat)\n","        y_hat = torch.select(y_hat, index=0, dim=1)\n","        \n","        loss = criterion(y_hat, y)\n","        \"\"\" Step 4. backward pass \"\"\"\n","        loss.backward()\n","        \"\"\" Step 5. optimization \"\"\"\n","        optimizer.step()\n","        \"\"\" Step 6. record loss \"\"\"\n","        train_loss += loss.item()\n","        \n","    train_loss = train_loss / len(train_loader)\n","    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n","    \n","    if counter%2==0:\n","        evaluate(model, train_loader)\n","        evaluate(model, test_loader)\n","    counter+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yx3fLKQvJzp1"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"training_2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}